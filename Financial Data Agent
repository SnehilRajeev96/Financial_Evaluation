1. Financial Data Agent 
Code
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
# Financial Data Agent Class
class FinancialDataAgent:
    def __init__(self, url):
        self.url = url

    # Fetch financial webpage
    def fetch_page(self):
        response = requests.get(self.url)
        if response.status_code == 200:
            return response.text
        else:
            raise Exception(f"Failed to retrieve data: {response.status_code}")
    # Parse HTML and extract data
    def extract_financial_data(self, html):
        soup = BeautifulSoup(html, 'html.parser')

        # Update these selectors based on actual website structure
        data = {
            'current_year_revenue': soup.select_one('.current-year-revenue').text.strip(),
            'previous_year_revenue': soup.select_one('.previous-year-revenue').text.strip(),
            'ebitda': soup.select_one('.ebitda').text.strip(),
            'net_profit': soup.select_one('.net-profit').text.strip(),
            'cash_flow_operations': soup.select_one('.cash-flow-operations').text.strip(),
            'total_employees': soup.select_one('.total-employees').text.strip(),
            'top_5_clients_revenue': soup.select_one('.top-5-clients-revenue').text.strip()
        }

        return data

    # Clean and convert data to numeric
    def clean_data(self, data):
        cleaned_data = {}
        for key, value in data.items():
            cleaned_data[key] = float(value.replace(',', '').replace('$', '').replace('%', ''))
        return cleaned_data

    # Calculate metrics based on formulas
    def calculate_metrics(self, data):
        metrics = {}

        # Revenue Growth Rate (YoY)
        metrics['revenue_growth_rate'] = ((data['current_year_revenue'] - data['previous_year_revenue']) / data['previous_year_revenue']) * 100

        # EBITDA Margin
        metrics['ebitda_margin'] = (data['ebitda'] / data['current_year_revenue']) * 100

        # Net Profit Margin
        metrics['net_profit_margin'] = (data['net_profit'] / data['current_year_revenue']) * 100

        # Cash Flow from Operations / Revenue
        metrics['cash_flow_operations_to_revenue'] = (data['cash_flow_operations'] / data['current_year_revenue']) * 100

        # Revenue per Employee
        metrics['revenue_per_employee'] = data['current_year_revenue'] / data['total_employees']

        # Client Concentration Risk
        metrics['client_concentration_risk'] = (data['top_5_clients_revenue'] / data['current_year_revenue']) * 100

        return metrics

    # Run agent
    def run(self):
        try:
            html = self.fetch_page()
            raw_data = self.extract_financial_data(html)
            cleaned_data = self.clean_data(raw_data)
            calculated_metrics = self.calculate_metrics(cleaned_data)
            return calculated_metrics

        except Exception as e:
            print(f"Error running Financial Data Agent: {e}")
            return None


# Example usage
if __name__ == "__main__":
    url = "https://investor.apple.com/investor-relations/default.aspx"

    agent = FinancialDataAgent(url)
    financial_metrics = agent.run()

    if financial_metrics:
        print(json.dumps(financial_metrics, indent=4))

2.Market Intelligence Agent
Code 
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json

class MarketIntelligenceAgent:
    def __init__(self, url, competitors_urls):
        self.url = url
        self.competitors_urls = competitors_urls

    def fetch_page(self, url):
        response = requests.get(url)
        if response.status_code == 200:
            return response.text
        else:
            raise Exception(f"Failed to retrieve data from {url}: {response.status_code}")

    def extract_data(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        data = {
            'company_revenue': float(soup.select_one('.company-revenue').text.replace('$', '').replace(',', '')),
            'total_addressable_market': float(soup.select_one('.market-size').text.replace('$', '').replace(',', '')),
            'regional_revenue_growth': float(soup.select_one('.regional-growth').text.replace('%', '')),
            'industry_diversification': int(soup.select_one('.industry-diversification').text.strip())
        }
        return data

    def extract_competitor_growth(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        return float(soup.select_one('.competitor-growth').text.replace('%', ''))

    def calculate_metrics(self, main_data, competitors_growth):
        metrics = {}
        
        # Global Market Share
        metrics['global_market_share'] = (main_data['company_revenue'] / main_data['total_addressable_market']) * 100

        # Competitive Benchmarking (relative growth vs peers)
        avg_competitor_growth = sum(competitors_growth) / len(competitors_growth)
        metrics['competitive_growth_difference'] = main_data['regional_revenue_growth'] - avg_competitor_growth

        # Regional Growth Trends
        metrics['regional_growth'] = main_data['regional_revenue_growth']

        # Client Base Diversification
        metrics['industry_diversification_score'] = main_data['industry_diversification']

        return metrics

    def run(self):
        try:
            main_html = self.fetch_page(self.url)
            main_data = self.extract_data(main_html)

            competitors_growth = []
            for comp_url in self.competitors_urls:
                comp_html = self.fetch_page(comp_url)
                competitors_growth.append(self.extract_competitor_growth(comp_html))

            metrics = self.calculate_metrics(main_data, competitors_growth)
            return metrics

        except Exception as e:
            print(f"Error running Market Intelligence Agent: {e}")
            return None

# Example usage
if __name__ == "__main__":
    company_url = "https://example.com/company/market"
    competitors_urls = [
        "https://example.com/competitor1",
        "https://example.com/competitor2",
        "https://example.com/competitor3"
    ]

    agent = MarketIntelligenceAgent(company_url, competitors_urls)
    market_metrics = agent.run()

    if market_metrics:
        print(json.dumps(market_metrics, indent=4))


3.Innovation/IP Agent
Code
import requests
from bs4 import BeautifulSoup
import json

class InnovationIPAgent:
    def __init__(self, company_url, patent_registry_url):
        self.company_url = company_url
        self.patent_registry_url = patent_registry_url

    def fetch_page(self, url):
        response = requests.get(url)
        if response.status_code == 200:
            return response.text
        else:
            raise Exception(f"Failed to retrieve data from {url}: {response.status_code}")

    def extract_company_data(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        data = {
            'rd_spend': float(soup.select_one('.rd-spend').text.replace('$', '').replace(',', '')),
            'total_revenue': float(soup.select_one('.total-revenue').text.replace('$', '').replace(',', '')),
            'ip_based_revenue': float(soup.select_one('.ip-based-revenue').text.replace('$', '').replace(',', '')),
        }
        return data

    def extract_patent_data(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        patent_count = int(soup.select_one('.patent-count').text.strip())
        return patent_count

    def calculate_metrics(self, company_data, patent_count, industry_patent_average):
        metrics = {}
        
        # Number of Patents (relative to peers)
        metrics['patent_count'] = patent_count
        metrics['patent_relative_score'] = (patent_count / industry_patent_average) * 100

        # R&D Spend as % of Revenue
        metrics['rd_spend_percentage'] = (company_data['rd_spend'] / company_data['total_revenue']) * 100

        # Proprietary Tools/Platforms (Productization Level)
        metrics['productization_level'] = (company_data['ip_based_revenue'] / company_data['total_revenue']) * 100

        return metrics

    def run(self, industry_patent_average):
        try:
            company_html = self.fetch_page(self.company_url)
            patent_html = self.fetch_page(self.patent_registry_url)

            company_data = self.extract_company_data(company_html)
            patent_count = self.extract_patent_data(patent_html)

            metrics = self.calculate_metrics(company_data, patent_count, industry_patent_average)
            return metrics

        except Exception as e:
            print(f"Error running Innovation/IP Agent: {e}")
            return None

# Example usage
if __name__ == "__main__":
    company_url = "https://example.com/company/innovation"
    patent_registry_url = "https://patents.example.com/company-patents"
    industry_patent_average = 25  # Example industry average for patents

    agent = InnovationIPAgent(company_url, patent_registry_url)
    innovation_metrics = agent.run(industry_patent_average)

    if innovation_metrics:
        print(json.dumps(innovation_metrics, indent=4))

4.ESG & Compliance Agent
Code
import requests
from bs4 import BeautifulSoup
import json
class ESGComplianceAgent:
    def __init__(self, esg_url, compliance_url):
        self.esg_url = esg_url
        self.compliance_url = compliance_url

    def fetch_page(self, url):
        response = requests.get(url)
        if response.status_code == 200:
            return response.text
        else:
            raise Exception(f"Failed to retrieve data from {url}: {response.status_code}")

    def extract_esg_data(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        data = {
            'esg_rating': soup.select_one('.esg-rating').text.strip(),
            'female_minority_leadership_percentage': float(soup.select_one('.dei-percentage').text.replace('%', ''))
        }
        return data

    def extract_compliance_data(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        certifications = [cert.text.strip() for cert in soup.select('.compliance-certifications li')]
        compliance_status = {
            'GDPR': 'GDPR' in certifications,
            'ISO': 'ISO' in certifications,
            'HIPAA': 'HIPAA' in certifications
        }
        return compliance_status

    def calculate_metrics(self, esg_data, compliance_data):
        metrics = {}

        # ESG Rating (Direct)
        metrics['esg_rating'] = esg_data['esg_rating']

        # DEI Metrics (Diversity & Inclusion)
        metrics['dei_leadership_percentage'] = esg_data['female_minority_leadership_percentage']

        # Regulatory Compliance
        metrics['gdpr_compliant'] = compliance_data['GDPR']
        metrics['iso_compliant'] = compliance_data['ISO']
        metrics['hipaa_compliant'] = compliance_data['HIPAA']

        return metrics

    def run(self):
        try:
            esg_html = self.fetch_page(self.esg_url)
            compliance_html = self.fetch_page(self.compliance_url)

            esg_data = self.extract_esg_data(esg_html)
            compliance_data = self.extract_compliance_data(compliance_html)

            metrics = self.calculate_metrics(esg_data, compliance_data)
            return metrics

        except Exception as e:
            print(f"Error running ESG & Compliance Agent: {e}")
            return None

# Example usage
if __name__ == "__main__":
    esg_url = "https://example.com/company/esg"
    compliance_url = "https://example.com/company/compliance"

    agent = ESGComplianceAgent(esg_url, compliance_url)
    esg_compliance_metrics = agent.run()

    if esg_compliance_metrics:
        print(json.dumps(esg_compliance_metrics, indent=4))

5.USPs/Competitive Edge Agent
Code
import requests
from bs4 import BeautifulSoup
import json

class USPsCompetitiveEdgeAgent:
    def __init__(self, company_url):
        self.company_url = company_url

    def fetch_page(self):
        response = requests.get(self.company_url)
        if response.status_code == 200:
            return response.text
        else:
            raise Exception(f"Failed to retrieve data from {self.company_url}: {response.status_code}")

    def extract_data(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        data = {
            'emerging_tech_revenue': float(soup.select_one('.emerging-tech-revenue').text.replace('$', '').replace(',', '')),
            'total_revenue': float(soup.select_one('.total-revenue').text.replace('$', '').replace(',', '')),
            'strategic_partnerships_count': int(soup.select_one('.partnership-count').text.strip()),
            'customer_satisfaction_score': float(soup.select_one('.nps-score').text.strip())
        }
        return data

    def calculate_metrics(self, data):
        metrics = {}

        # Niche Capabilities (emerging tech revenue %)
        metrics['niche_capabilities_percentage'] = (data['emerging_tech_revenue'] / data['total_revenue']) * 100

        # Strategic Partnerships & Alliances
        metrics['strategic_partnerships'] = data['strategic_partnerships_count']

        # Customer Satisfaction (NPS or CSAT)
        metrics['customer_satisfaction'] = data['customer_satisfaction_score']

        return metrics

    def run(self):
        try:
            html = self.fetch_page()
            extracted_data = self.extract_data(html)
            metrics = self.calculate_metrics(extracted_data)
            return metrics

        except Exception as e:
            print(f"Error running USPs/Competitive Edge Agent: {e}")
            return None

# Example usage
if __name__ == "__main__":
    company_url = "https://example.com/company/competitive-edge"

    agent = USPsCompetitiveEdgeAgent(company_url)
    competitive_edge_metrics = agent.run()

    if competitive_edge_metrics:
        print(json.dumps(competitive_edge_metrics, indent=4))

6.Coordinator Agent
Code 
import json
# Import your agents (assuming they are saved in separate files)
from financial_agent import FinancialDataAgent
from market_agent import MarketIntelligenceAgent
from innovation_ip_agent import InnovationIPAgent
from esg_compliance_agent import ESGComplianceAgent
from usps_competitive_agent import USPsCompetitiveEdgeAgent

class CoordinatorAgent:
    def __init__(self, config):
        self.config = config

    def run_agents(self):
        results = {}

        # Run Financial Data Agent
        financial_agent = FinancialDataAgent(self.config['financial_url'])
        results['financial_data'] = financial_agent.run()

        # Run Market Intelligence Agent
        market_agent = MarketIntelligenceAgent(
            self.config['market_url'],
            self.config['competitors_urls']
        )
        results['market_intelligence'] = market_agent.run()

        # Run Innovation/IP Agent
        innovation_agent = InnovationIPAgent(
            self.config['innovation_url'],
            self.config['patent_registry_url']
        )
        results['innovation_data'] = innovation_agent.run(self.config['industry_patent_average'])

        # Run ESG & Compliance Agent
        esg_agent = ESGComplianceAgent(
            self.config['esg_url'],
            self.config['compliance_url']
        )
        results['esg_compliance'] = esg_agent.run()

        # Run USPs/Competitive Edge Agent
        usps_agent = USPsCompetitiveEdgeAgent(self.config['usps_url'])
        results['competitive_edge'] = usps_agent.run()

        return results

# Example usage
if __name__ == "__main__":
    config = {
        "financial_url": "https://example.com/company/financials",
        "market_url": "https://example.com/company/market",
        "competitors_urls": [
            "https://example.com/competitor1",
            "https://example.com/competitor2"
        ],
        "innovation_url": "https://example.com/company/innovation",
        "patent_registry_url": "https://patents.example.com/company-patents",
        "industry_patent_average": 25,
        "esg_url": "https://example.com/company/esg",
        "compliance_url": "https://example.com/company/compliance",
        "usps_url": "https://example.com/company/competitive-edge"
    }

    coordinator = CoordinatorAgent(config)
    aggregated_results = coordinator.run_agents()

    print(json.dumps(aggregated_results, indent=4))


Calculation and Scoring Agent
Code
import json
class CalculationScoringAgent:
    def __init__(self, aggregated_data):
        self.data = aggregated_data

    def score_range(self, value, ranges):
        for score, (low, high) in ranges.items():
            if low <= value < high:
                return score
        return max(ranges.keys())  # Default to highest score if value exceeds all ranges

    def calculate_scores(self):
        scores = {}
        weights = {
            'financial': 40,
            'market': 20,
            'innovation': 15,
            'competitive_edge': 15,
            'esg_compliance': 10
        }

        # --- Financial Performance Scoring ---
        fin = self.data['financial_data']
        scores['revenue_growth'] = self.score_range(fin['revenue_growth_rate'], {
            1: (0, 10), 2: (10, 20), 3: (20, 30), 4: (30, 40), 5: (40, float('inf'))
        })
        scores['ebitda_margin'] = self.score_range(fin['ebitda_margin'], {
            1: (0, 10), 2: (10, 20), 3: (20, 25), 4: (25, 30), 5: (30, float('inf'))
        })
        scores['net_profit_margin'] = self.score_range(fin['net_profit_margin'], {
            1: (0, 5), 2: (5, 10), 3: (10, 15), 4: (15, 20), 5: (20, float('inf'))
        })

        # --- Market Position Scoring ---
        market = self.data['market_intelligence']
        scores['market_share'] = self.score_range(market['global_market_share'], {
            1: (0, 2), 2: (2, 5), 3: (5, 10), 4: (10, 15), 5: (15, float('inf'))
        })
        scores['regional_growth'] = self.score_range(market['regional_growth'], {
            1: (0, 10), 2: (10, 15), 3: (15, 20), 4: (20, 30), 5: (30, float('inf'))
        })

        # --- Innovation Scoring ---
        innovation = self.data['innovation_data']
        scores['rd_spend'] = self.score_range(innovation['rd_spend_percentage'], {
            1: (0, 1), 2: (1, 3), 3: (3, 5), 4: (5, 10), 5: (10, float('inf'))
        })
        scores['productization'] = self.score_range(innovation['productization_level'], {
            1: (0, 5), 2: (5, 10), 3: (10, 15), 4: (15, 20), 5: (20, float('inf'))
        })

        # --- Competitive Edge Scoring ---
        ce = self.data['competitive_edge']
        scores['niche_capabilities'] = self.score_range(ce['niche_capabilities_percentage'], {
            1: (0, 10), 2: (10, 20), 3: (20, 25), 4: (25, 30), 5: (30, float('inf'))
        })
        scores['partnerships'] = self.score_range(ce['strategic_partnerships'], {
            1: (0, 2), 2: (2, 4), 3: (4, 6), 4: (6, 10), 5: (10, float('inf'))
        })

        # --- ESG & Compliance Scoring ---
        esg = self.data['esg_compliance']
        scores['dei'] = self.score_range(esg['dei_leadership_percentage'], {
            1: (0, 10), 2: (10, 20), 3: (20, 30), 4: (30, 40), 5: (40, float('inf'))
        })
        scores['compliance'] = 5 if esg['gdpr_compliant'] and esg['iso_compliant'] else 3

        return scores

    def compute_final_score(self, scores):
        weighted_scores = {
            'financial': (scores['revenue_growth'] + scores['ebitda_margin'] + scores['net_profit_margin']) / 3,
            'market': (scores['market_share'] + scores['regional_growth']) / 2,
            'innovation': (scores['rd_spend'] + scores['productization']) / 2,
            'competitive_edge': (scores['niche_capabilities'] + scores['partnerships']) / 2,
            'esg_compliance': (scores['dei'] + scores['compliance']) / 2
        }

        final_score = sum(weighted_scores[key] * weight for key, weight in {
            'financial': 0.40,
            'market': 0.20,
            'innovation': 0.15,
            'competitive_edge': 0.15,
            'esg_compliance': 0.10
        }.items())

        return round(final_score, 2)

    def run(self):
        scores = self.calculate_scores()
        final_score = self.compute_final_score(scores)
        return {
            'parameter_scores': scores,
            'final_weighted_score': final_score
        }

# Example usage
if __name__ == "__main__":
    with open('aggregated_results.json') as f:
        aggregated_data = json.load(f)

    agent = CalculationScoringAgent(aggregated_data)
    result = agent.run()
    print(json.dumps(result, indent=4))


